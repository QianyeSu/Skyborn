name: Test Coverage and Quality

on:
  push:
    branches: [main]
    paths:
      - "src/**"
      - "tests/**"
      - "requirements*.txt"
      - "pyproject.toml"
  pull_request:
    branches: [main]
  workflow_dispatch:

jobs:
  coverage:
    name: Code Coverage Analysis
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # Fetch full history for coverage comparison

      - name: Set up Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y libeccodes-dev

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .
          pip install pytest pytest-cov pytest-xdist coverage[toml]
          # Try to install eccodes, but don't fail if it doesn't work
          pip install eccodes || echo "eccodes installation failed, continuing without it"

      - name: Run tests with coverage
        run: |
          pytest tests/ \
            --cov=src/skyborn \
            --cov-omit="src/skyborn/windspharm/*,src/skyborn/spharm/*" \
            --cov-report=xml \
            --cov-report=html \
            --cov-report=term-missing \
            --cov-fail-under=50 \
            -v --tb=short || true

      - name: Check if coverage files exist
        run: |
          echo "Checking for coverage files..."
          ls -la coverage.xml || echo "coverage.xml not found"
          ls -la htmlcov/ || echo "htmlcov directory not found"

      - name: Generate coverage report even if tests failed
        if: always()
        run: |
          # If coverage.xml doesn't exist, try to generate it manually
          if [ ! -f coverage.xml ]; then
            echo "Attempting to generate coverage report manually..."
            coverage xml --fail-under=0 || echo "Failed to generate coverage.xml"
          fi

      - name: Upload coverage to Codecov
        if: always()
        uses: codecov/codecov-action@v5
        with:
          files: ./coverage.xml
          flags: unittests
          name: skyborn-coverage
          fail_ci_if_error: false
          verbose: true
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}

      - name: Upload coverage reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report
          path: htmlcov/
        continue-on-error: true

  # Performance benchmarks
  performance:
    name: Performance Benchmarks
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .
          pip install pytest-benchmark memory-profiler numpy xarray

      - name: Run performance tests
        run: |
          python -c "
          import time
          import numpy as np
          import xarray as xr
          import skyborn

          print('Performance benchmarks:')

          # Test longitude conversion performance with correct xarray usage
          data = np.random.rand(1000, 1000)
          lon_coords = np.arange(1000)
          lat_coords = np.arange(1000)
          da = xr.DataArray(data, coords=[lat_coords, lon_coords], dims=['lat', 'lon'])
          start = time.time()
          converted = skyborn.convert_longitude_range(da, lon='lon', center_on_180=True)
          end = time.time()
          print(f'Longitude conversion (1000x1000): {end-start:.4f}s')

          # Test gradient calculation performance (1D)
          data_1d = np.random.rand(1000)
          coords_1d = np.linspace(-90, 90, 1000)
          start = time.time()
          grad = skyborn.calculate_gradient(data_1d, coords_1d)
          end = time.time()
          print(f'Gradient calculation (1000 points): {end-start:.4f}s')

          print('Performance tests completed!')
          "

  # Documentation build test
  docs:
    name: Documentation Build Test
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e .
          pip install -r requirements-docs.txt

      - name: Test documentation build
        run: |
          cd docs
          sphinx-build -b html source build/html --quiet

      - name: Upload docs artifacts
        uses: actions/upload-artifact@v4
        with:
          name: documentation
          path: docs/build/html/
